# Required API Keys
ANTHROPIC_API_KEY="your-anthropic-api-key" # Needed if proxying *to* Anthropic
OPENAI_API_KEY="sk-..."
GEMINI_API_KEY="your-google-ai-studio-key"

# Optional: Provider Preference and Model Mapping
# Controls which provider (google, openai, or anthropic) is preferred for mapping haiku/sonnet.
# Defaults to openai if not set.
# Set to "anthropic" for "just an Anthropic proxy" mode (no remapping)
PREFERRED_PROVIDER="openai"
OPENAI_BASE_URL="https://api.openai.com/v1"

# Optional: Specify the exact models to map haiku/sonnet to.
# If PREFERRED_PROVIDER=google, these MUST be valid Gemini model names known to the server.
# Defaults to gemini-2.5-pro and gemini-2.5-flash if PREFERRED_PROVIDER=google.
# Defaults to gpt-4.1 and gpt-4.1-mini if PREFERRED_PROVIDER=openai.
# These are IGNORED when PREFERRED_PROVIDER=anthropic (models are not remapped).
# BIG_MODEL="gpt-4.1"
# SMALL_MODEL="gpt-4.1-mini"

# Example Google mapping:
# PREFERRED_PROVIDER="google"
# BIG_MODEL="gemini-2.5-pro"
# SMALL_MODEL="gemini-2.5-flash"

# Example Google with vertex AI auth via ADC:
# PREFERRED_PROVIDER="google"
# USE_VERTEX_AUTH=true
# BIG_MODEL="gemini-2.5-pro"
# SMALL_MODEL="gemini-2.5-flash"

# Optional: Pass through incoming API keys
# When enabled, extracts API key from x-api-key or Authorization Bearer headers
# and forwards it to upstream services instead of using static API keys above
# Useful for multi-tenant environments with per-user quota tracking
# PASSTHROUGH_API_KEY="false"

# Example "just an Anthropic proxy" mode:
# PREFERRED_PROVIDER="anthropic"
# (BIG_MODEL and SMALL_MODEL are ignored in this mode)
